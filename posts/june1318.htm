<!DOCTYPE html>

<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="computer and data science blog">
  <meta name="author" content="michalis despotopoulos">
  <link rel="icon" href="../img/fav32.png">

  <title>A day In life: June 13, 2018</title>

  <!-- Bootstrap core CSS -->
  <link href="../dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">
  <!-- Custom styles for this template -->
  <link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
  <link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="../style.css" media="screen">
  <link rel="icon" href="./img/fav32.ico" type="image/gif">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-119754085-1"></script>
  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-119754085-1');
  </script>
  <script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/embed.js"
  data-dojo-config="usePlainJson: true, isDebug: false"></script><script
  type="text/javascript">
  require(["mojo/signup-forms/Loader"],
  function(L) { L.start({"baseUrl":"mc.us18.list-manage.com","uuid":"0949a3f68a174be9eb47e487f","lid":"2597c8fdeb"}) })
  </script>
  <!-- Hotjar Tracking Code -->
  <script>
  (function(h,o,t,j,a,r){
    h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
    h._hjSettings={hjid:918288,hjsv:6};
    a=o.getElementsByTagName('head')[0];
    r=o.createElement('script');r.async=1;
    r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
    a.appendChild(r);
  })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
  </script>
</head>

<body>
  <div class="container">
    <header class="blog-header py-3">
      <div class="row flex-nowrap justify-content-between align-items-center">
        <div class="col-4 pt-1 justify-content-start">
          <a class="text-muted" href="https://mailchi.mp/189317a0a55f/adayinlife"><img class="subscribe" src="../img/subscribe.png"></img></a>
        </div>
        <div class="col-4 text-center">
          <img class="logo img-fluid" src="../img/logo-desktop.png" alt="logo" border="1">
          <!--<a class="blog-header-logo text-dark" href="#"><span class=redLetter>A</span> day <span class=redLetter>I</span>n life</a>-->
        </div>
        <div class="col-4 d-flex justify-content-end align-items-center">
          <a class="text-muted" href="../rss.xml">
            <img class=rss src="../img/rss.png"></img>
            <!--<svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="mx-3"><circle cx="10.5" cy="10.5" r="7.5"></circle><line x1="21" y1="21" x2="15.8" y2="15.8"></line></svg>-->
          </a>
          <!--<a class="btn btn-sm btn-outline-secondary" href="#">Sign up</a>-->
        </div>
      </div>
    </header>

<div class="nav-scroller py-1 mb-2">
  <nav class="nav d-flex justify-content-between">
    <a class="p-2 text-muted" href="../index.htm">Home</a>
  </nav>
</div>
<div class="content">
  <div class = "date">June 13, 2018</div>
  <h3 class="postTitle">Just enough to get you started with Apache Spark</h3>
  <h3 class="paragraphTitle">Introduction</h3>
  <p>
    When Big Data became a thing some years ago, I tried several frameworks,
    platforms and technologies. Most, if not all of them were not so good at hiding
    their inherent distributed nature, which caused a steep learning curve
    and increased complexity. The first thing I noticed in Apache Spark was
    the fact that it managed to create such abstractions, that it could
    hide all the ugly parts. It managed to do that in a way that you
    feel you are just manipulating in-memory data structures in some
    high-level programming language - like a HashSet in Java. You know, the usual stuff.
    This guide is meant to be a bare minimum tutorial for people who have
    never seen Spark before or has been a while since they last played with it.
  </p>
  <h3 class="paragraphTitle">Apache Spark</h3>
  <p>
    Apache Spark is an analytics framework in a distributed computing environment,
    originally developer at UC Berkeley in 2009 (later donated to the Apache Software Foundation).
    It supports several languages such as Python, Scala and Java and can be
    used for Big Data and Machine Learning purposes.
  </p>
  <p>
    It is important to remember that in the heart of Spark, there is the
    Resilient Distributed Dataset (RDD), the core data structure of Spark.
    We are going to talk about RDDs shortly.
    Spark comes with different components to make sure it spans across
    several fields and technologies:
    <ul>
      <li>Spark Core: Spark’s distributed execution engine.</li>
      <li>Spark SQL: Support for SQL queries.</li>
      <li>Spark Streaming: Stream processing of live data streams.</li>
      <li>GraphX: API for graphs.</li>
      <li>MLlib: Machine Learning in Spark.</li>
    </ul>
  </p>
  <img class=imageSmall src="../img/daft_spark.png" alt="Daft Spark" border="1">
  <h3 class="paragraphTitle">Harder, Better, Faster, Stronger (Spark vs. Hadoop MapReduce)</h3>
  <p>
    Since we already have Hadoop MapReduce, why use Apache Spark instead for data processing?
    A key difference here is that while Hadoop MapReduce uses the <b>disk</b> to persist
    intermediate results, Spark processes data <b>in-memory</b>.
    This makes Spark much faster and can be proven critical in real time
    applications such as stream processing. Spark may be up to 100 times faster.
    However, in batch processing where time is not critical but also the
    extra disk space might be handy i.e. large datasets, Hadoop MapReduce
    is still competitive. Finally Spark’s components allow for SQL queries,
    Graph algorithms and Machine Learning. To recap, what we get with Spark:
    <ul>
      <li>
        Easier programming. Because of its abstractions
        the programmer does not need to know about any internals.
      </li>
      <li>
        You get to start Spark from a Command Line Interface!
        It can be as easy as start the CLI, load a file and start processing it.
      </li>
      <li>Faster stream processing.</li>
      <li>SQL queries!</li>
    </ul>
  </p>
  <h3 class="paragraphTitle">RDDs</h3>
  <p>
    RDDs are fundamental data structures of Spark along with the Dataframes.
    They are an abstraction which hides a lot of complicated details.
    All you need to know is their API and not necessarily what it is going on
    under the hood. The abbreviation breaks down as:
    <ul>
      <li>
        <b>Resilient</b>, which means they are fault-tolerant:
        recompute missing or even damaged partitions due to node failures.
      </li>
      <li><b>Distributed</b>, since they act on multiple nodes in a cluster.</li>
      <li>
        <b>Dataset</b> is a collection of partitioned data with primitive values
        or values of values, e.g. tuples or other objects.
      </li>
    </ul>
  </p>
  <p>
    There are three ways to create an RDD in Spark:
    <ul>
      <li>Parallelizing an already existing collection in your driver program</li>
      <li>Referencing a dataset in an external storage system, e.g. HDFS</li>
      <li>Creating an RDD from already existing RDDs</li>
    </ul>
  </p>
  <h3 class="paragraphTitle">Basic RDD API</h3>
  <p>
    RDDs offer an API which can be used to handle their lifecycle.
    You can read the fairly long API from the
    <a href="https://spark.apache.org/docs/2.2.0/api/scala/index.html#package">official source</a>
    but you can get a taste with the following:
    <h4 class="paragraphTitleSmall">Parallelize</h4>
    <p>
      One of the most common operations is "parallelize".
      It takes as an argument a collection such as an array and it essentially
      does what the name suggests: copies the data to a distributed setting where we can run operations in parallel.
      Let’s see what the code (Scala) looks like:
      <div class="boxed">
        1. val spark = SparkSession.builder() </br>
        2. val myRdd = spark.sparkContext.parallelize(Array(1, 2, 3, 4, 5))
      </div>
      That’s it. You created a spark context which is the very first object you
      create when developing a Spark SQL app and "parallelized" a given dataset.
    </p>
    <h4 class="paragraphTitleSmall">Collect</h4>
    <p>
      Returns all the elements of the dataset as an array at the driver program
      (i.e. the master node). In some sense this is the reverse of "parallelize",
      calling the data back to the driver program.
      Note that this is a memory intensive call
      and should be used after a "filter" or similar size reducing operation,
      otherwise it can easily cause a memory exception if the dataset is too
      large to fit in memory. A safe alternative is to use "take" instead,
      in order to see a part of the data.
    </p>
  </p>

  <h3 class="paragraphTitle">Dataframes</h3>
  <p>
    Dataframes are another abstraction built on top of RDDs, which means they are
    an even higher abstraction. As the official Spark guide says, you can
    create DataFrames from an existing RDD, from a Hive table, or from Spark
    data sources (e.g. text file, Parquet file, JSON, etc.). Roughly, you can
    think of RDDs as operating on key/value datasets and dataframes on matrices
    (like SQL tables). If you are familiar with R, they are very similar
    abstractions with R's dataframes.
    Let’s see how to create one from a JSON file right away:
    <div class="boxed">
      1. val df = spark.read.json("path/grades.json") </br>
      2. df.createOrReplaceTempView("grades") </br>
      3. val sqlDF = spark.sql("SELECT * FROM grades") </br>
      4. sqlDF.show()
    </div>
  </p>

  <p>
    In line 1, we create a dataframe from a JSON which contains a student's grade
    along with its grade in a course. Line 2 creates a view which is the equivalent
    of a database table. We call this "grades". In line 3 we declare the SQL query we
    want to run and finally in line 4 we display the results. Simple as that!
  </p>

  <p>
    Taking it from here, this is where magic happens.
    You are free to experiment with the API and try numerous processing functions, e.g. map, reduce, filter etc.
    There is a lot going, on of increasing complexity, which you can pick up by consulting the official API.
  </p>
  <p>Credits to <a href="https://www.linkedin.com/in/christos-mantas-2b79a9107/">Christos Mantas</a> for sharing his expertise on Spark.
    <div class="just-comments"
    data-apikey="9fa1f1f5-2ca0-4d89-bb34-b78c48fafcb1"
    data-hideattribution="true">
  </div>
  <script async src="https://just-comments.com/w.js"></script>
</div> <!-- content -->
</div> <!-- container -->

<!-- Footer -->
<footer class="page-footer font-small unique-color-dark mt-4">

  <div style="background-color: #82AFA9;">
    <div class="container">

      <!-- Grid row-->
      <div class="row py-4 d-flex align-items-center">

        <!-- Grid column -->
        <div class="col-md-6 col-lg-5 text-center text-md-left mb-4 mb-md-0">
          <h6 class="mb-0"></h6>
        </div>
        <!-- Grid column -->

        <!-- Grid column -->
        <div class="col-md-6 col-lg-7 text-center text-md-right">
          <!-- Facebook -->
          <a class="fb-ic" href="https://www.facebook.com/adayinlifeblogging/">
            <i class="fa fa-facebook white-text mr-4"> </i>
          </a>
          <!-- Twitter -->
          <a class="tw-ic" href="https://twitter.com/mdespotopoulos?lang=en">
            <i class="fa fa-twitter white-text mr-4"> </i>
          </a>
          <!--Linkedin -->
          <a class="li-ic" href="https://www.linkedin.com/in/mdespotopoulos/">
            <i class="fa fa-linkedin white-text mr-4"> </i>
          </a>
          <a class="li-ic" href="https://www.linkedin.com/in/mdespotopoulos/">
            <i class="fa fa-github white-text mr-4"> </i>
          </a>
        </div>
        <!-- Grid column -->

      </div>
      <!-- Grid row-->

    </div>
  </div>

  <!-- Footer Links -->
  <div class="container text-center text-md-left mt-5">

    <!-- Grid row -->
    <div class="row mt-3">

      <!-- Grid column -->
      <div class="col-md-3 col-lg-4 col-xl-3 mx-auto mb-4">

        <!-- Content -->
        <h6 class="text-uppercase font-weight-bold">A day In life</h6>
        <hr class="deep-purple accent-2 mb-4 mt-0 d-inline-block mx-auto" style="width: 60px;">
        <p>Get in touch if you didn't find what you were looking for or you just want to say hi!</p>

      </div>
      <!-- Grid column -->
      <!-- Grid column -->
      <div class="col-md-3 col-lg-2 col-xl-2 mx-auto mb-4">

        <!-- Links -->
        <h6 class="text-uppercase font-weight-bold">Useful links</h6>
        <hr class="deep-purple accent-2 mb-4 mt-0 d-inline-block mx-auto" style="width: 60px;">
        <p>
          <a href="../privacy.htm">Privacy Policy</a>
        </p>
        <p>
          <a href="../terms.htm">Terms of Use</a>
        </p>
      </div>
      <!-- Grid column -->
      <!-- Grid column -->
      <div class="col-md-4 col-lg-3 col-xl-3 mx-auto mb-md-0 mb-4">

        <!-- Links -->
        <h6 class="text-uppercase font-weight-bold">Contact</h6>
        <hr class="deep-purple accent-2 mb-4 mt-0 d-inline-block mx-auto" style="width: 60px;">
        <p>
          <i class="fa fa-envelope mr-3"></i> michael@adayinlife.ml
        </p>
      </div>
      <!-- Grid column -->

    </div>
    <!-- Grid row -->

  </div>
  <!-- Footer Links -->

  <!-- Copyright -->
  <div class="footer-copyright text-center py-3">© 2018 Copyright:
    <a href="https://adayinlife.ml"> adayinlife.ml</a>
  </div>
  <!-- Copyright -->

</footer>
<!-- Footer -->
</body>
</html>
